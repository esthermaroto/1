from rich import print
from clients.llm_client import create_openai_client, get_model_name
from services.token_counter import count_tokens

def get_title_generation_prompts(description, retry=False, original_title=None):
    """Generate system and user prompts for title generation"""
    system_prompt = ("Eres un experto en generar t칤tulos atractivos para YouTube. "
                    "Genera un 칰nico t칤tulo de m치ximo 70 caracteres en base a la descripci칩n proporcionada. "
                    "No incluyas comillas, ni simples ni dobles, ni corchetes. "
                    "Debe ser claro, atractivo y optimizado para SEO. "
                    "Devuelve solo el t칤tulo, sin ning칰n otro texto adicional. "                            
                    "Usa un tono divertido y atractivo. "
                    "Usa emojis si es posible. "
                    "Si se indica en la descripci칩n que es un cap칤tulo, a침ade el capitulo al final del t칤tulo. "
                    "Usando la abreviatura 'Cap.' y el n칰mero del cap칤tulo."
                    "Si no se indica que es un cap칤tulo, o que es el v칤deo de una serie, no lo incluyas.")
    
    user_prompt = description
    
    # Si es un reintento, modificar los prompts para acortar el t칤tulo original
    if retry and original_title:
        system_prompt += "Aseg칰rate ABSOLUTAMENTE de que no supere los 70 caracteres. "
        system_prompt += "Este es un reintento para acortar un t칤tulo. "
        system_prompt += "Tu respuesta debe tener menos de 70 caracteres. Es CR칈TICO. "
        system_prompt += "IMPORTANTE: Si el t칤tulo tiene m치s de 70 caracteres, SER츼 RECHAZADO. "
        
        user_prompt = f"Este t칤tulo es demasiado largo (tiene {len(original_title)} caracteres): '{original_title}'. "
        user_prompt += f"Por favor ac칩rtalo manteniendo la esencia y las palabras clave importantes. "
        user_prompt += f"Aseg칰rate absolutamente de que no supere los 70 caracteres."
    
    return system_prompt, user_prompt

def generate_title(source, model_name, description, retry=False, original_title=None):
    """
    Generate a title based on the provided parameters and yield stream response
    
    Args:
        source (str): 'github' or 'ollama'
        model_name (str): Name of the model to use
        description (str): Description to base the title on
        retry (bool): Whether this is a retry attempt
        original_title (str): Original title if this is a retry
    
    Yields:
        str: Chunks of the generated title
    """
    if source not in ['github', 'ollama']:
        yield f"游뱂 Unknown source: {source}\n"
        return

    try:
        client = create_openai_client(source)
        if not client:
            yield f"游녩游낕 Failed to create client for source: {source}"
            return

        system_prompt, user_prompt = get_title_generation_prompts(
            description, retry, original_title
        )
        
        if retry and original_title:
            print(f"[bold red]REINTENTO SOLICITADO[/bold red]: Acortar t칤tulo de {len(original_title)} caracteres")
            yield "Acortando t칤tulo..."

        # Count tokens for logging
        token_count, _ = count_tokens(system_prompt + user_prompt)
        print(f"[bold yellow]Tokens used[/bold yellow]: {token_count}")
        
        # Prepare API parameters
        params = {
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            "stream": True,
            "temperature": 0.9,
            "model": get_model_name(source, model_name)
        }
        
        stream_response = client.chat.completions.create(**params)
        
        full_response = ""
        for chunk in stream_response:
            if chunk.choices and len(chunk.choices) > 0 and chunk.choices[0].delta.content is not None:
                content = chunk.choices[0].delta.content
                full_response += content
                yield content
        
        # Log the result
        color = "green" if len(full_response) <= 70 else "red"
        print(f"[bold {color}]Longitud final: {len(full_response)} caracteres[/bold {color}]")
        print(f"[bold blue]T칤tulo generado: {full_response}[/bold blue]")

    except Exception as e:
        error_message = f"游뱄 Error using OpenAI SDK with {source}: {str(e)}"
        print(f"[bold red]ERROR[/bold red]: {error_message}")
        yield error_message